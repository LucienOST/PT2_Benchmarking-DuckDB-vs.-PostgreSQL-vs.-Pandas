{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eac1050c",
   "metadata": {},
   "source": [
    "# Testing in-memory data loads and exports with Pandas\n",
    "\n",
    "In this notebook, the loading (in-memory) and exporting capabilities of Pandas are tested. The following steps are processes: <br>\n",
    "\n",
    "- Loading data from multiple csv files into one dataframe (around 20 files of different sizes)\n",
    "- Loading data from one big csv file (3.2 million rows)\n",
    "- Exporting the data from dataframe and table into a parquet file.\n",
    "\n",
    "Prerequisite to run this script: \n",
    "- The preceding notebook \"data_setup/00_Get_Data.ipynb\" must be executed before which stores the csv file under the referred directories.\n",
    "- **Increase buffer size** when running locally  <code> jupyter notebook --NotebookApp.max_buffer_size = your_value*</code>\n",
    " \n",
    " *your_value = desired buffer size in bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66568c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import psutil\n",
    "from pathlib import Path\n",
    "import pyarrow\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13c72dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_dir = Path().cwd().parent.absolute()\n",
    "sys.path.insert(0, str(app_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "451e3663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.functions import monitor_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ad56bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial variable for the directory\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232372da",
   "metadata": {},
   "source": [
    "# Test 1: Loading from Multiple Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e347dda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the GWR csv files on canton level\n",
    "os.chdir(path)\n",
    "os.chdir(\"..\\datasets\\GWR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f930f2a",
   "metadata": {},
   "source": [
    "### Loading with Pandas (in-memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afe3defc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Usage: 0.2%\n",
      "Memory Usage: 44.4%\n",
      "Pandas load time: 4.291918516159058\n",
      "Number of dataframe rows: 2573168\n",
      "CPU Usage: 0.4%\n",
      "Memory Usage: 47.1%\n"
     ]
    }
   ],
   "source": [
    "monitor_usage()\n",
    "ct = time.time()\n",
    "cantons_df_pandas = pd.concat([pd.read_csv(f, on_bad_lines='skip', sep='\\t') for f in glob.glob('*.csv')])\n",
    "print(f\"Pandas load time: {(time.time() - ct)}\")\n",
    "print(f\"Number of dataframe rows: {cantons_df_pandas.shape[0]}\")\n",
    "monitor_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7782b450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EGID</th>\n",
       "      <th>EDID</th>\n",
       "      <th>EGAID</th>\n",
       "      <th>DEINR</th>\n",
       "      <th>ESID</th>\n",
       "      <th>STRNAME</th>\n",
       "      <th>STRNAMK</th>\n",
       "      <th>STRINDX</th>\n",
       "      <th>STRSP</th>\n",
       "      <th>STROFFIZIEL</th>\n",
       "      <th>DPLZ4</th>\n",
       "      <th>DPLZZ</th>\n",
       "      <th>DPLZNAME</th>\n",
       "      <th>DKODE</th>\n",
       "      <th>DKODN</th>\n",
       "      <th>DOFFADR</th>\n",
       "      <th>DEXPDAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>520001</td>\n",
       "      <td>0</td>\n",
       "      <td>100428604</td>\n",
       "      <td>43</td>\n",
       "      <td>10109554.0</td>\n",
       "      <td>Schiffl채ndestrasse</td>\n",
       "      <td>Schiffl채ndestr.</td>\n",
       "      <td>Sch</td>\n",
       "      <td>9901.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>Aarau</td>\n",
       "      <td>2645359.617</td>\n",
       "      <td>1249365.315</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-06-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     EGID  EDID      EGAID DEINR        ESID             STRNAME  \\\n",
       "0  520001     0  100428604    43  10109554.0  Schiffl채ndestrasse   \n",
       "\n",
       "           STRNAMK STRINDX   STRSP  STROFFIZIEL  DPLZ4  DPLZZ DPLZNAME  \\\n",
       "0  Schiffl채ndestr.     Sch  9901.0          1.0   5000      0    Aarau   \n",
       "\n",
       "         DKODE        DKODN  DOFFADR     DEXPDAT  \n",
       "0  2645359.617  1249365.315      1.0  2023-06-24  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the structure\n",
    "cantons_df_pandas.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea87379",
   "metadata": {},
   "source": [
    "# Test 2: Loading from Single File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6371e145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the single GWR csv file (whole Switzerland)\n",
    "os.chdir(path)\n",
    "os.chdir(\"..\\datasets\\GWR\\GWR_Total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ef655a",
   "metadata": {},
   "source": [
    "### Loading with Pandas (in-memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b10d734c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Usage: 0.0%\n",
      "Memory Usage: 47.1%\n",
      "Pandas load time: 4.8594348430633545\n",
      "Number of dataframe rows: 3262598\n",
      "CPU Usage: 0.6%\n",
      "Memory Usage: 50.4%\n"
     ]
    }
   ],
   "source": [
    "monitor_usage()\n",
    "ct = time.time()\n",
    "switzerland_df_pandas = pd.read_csv('eingang_entree_entrata_total.csv', on_bad_lines='skip', sep='\\t') \n",
    "print(f\"Pandas load time: {(time.time() - ct)}\")\n",
    "print(f\"Number of dataframe rows: {switzerland_df_pandas.shape[0]}\")\n",
    "monitor_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73817bbb",
   "metadata": {},
   "source": [
    "## Initial Results: \n",
    "In the **first scenario**, DuckDB was up to **2.5sec faster** than Pandas. Or when considered the whole loading time, around **50% faster**. However, this advantage play only out as long as the referenced object fits into memory. For the **second scenario**, DuckDB also performed better. However, DuckDB was not able to read the data in one transaction first. This works only with an increased memory buffer for the notebook kernel.\n",
    "<br> <br>\n",
    "Also worth mentioning: There is less code required in DuckDB to achieve the same results. For instance, no separator sign needs to be determined in DuckDB when reading the csv file. Conversely in Pandas, there will be an error when using a CSV file where the data is not separated with a comma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466f79f6",
   "metadata": {},
   "source": [
    "# Export dataframe to parquet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08fb34be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Usage: 1.0%\n",
      "Memory Usage: 50.3%\n",
      "Pandas load time: 2.8576462268829346\n",
      "CPU Usage: 0.6%\n",
      "Memory Usage: 51.9%\n"
     ]
    }
   ],
   "source": [
    "monitor_usage()\n",
    "ct = time.time()\n",
    "cantons_df_pandas.to_parquet('cantons_gwr_pandas.parquet.gzip', engine='auto', compression='snappy',\n",
    "              index=None, partition_cols=None, storage_options=None)\n",
    "print(f\"Pandas load time: {(time.time() - ct)}\")\n",
    "monitor_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cd4a6c",
   "metadata": {},
   "source": [
    "The export to parquet with DuckDB is 50% faster than with Pandas!<br>\n",
    "*Note: Pandas requires an additional library **(pyarrow)** to export the dataframe as a parquet file.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
